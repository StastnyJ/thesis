\chapter{\abstractname}

Simultaneous localization and mapping is a crucial problem for most autonomous mobile robots. RatSLAM is a biologically inspired SLAM system that simulates the rodent's brain using the Pose Cell network, odometry, and visual input. This system demonstrates long-term stability and accurate results in indoor and outdoor environments. One of the essential parts of RatSLAM is a scene recognition algorithm. Whereas RatSLAM uses a visual scene recognition approach, this work suggests a technique to combine data from 3D LiDAR and camera to achieve better scene recognition results and hence improve the whole SLAM system. Compared to the camera, the LiDAR sensor is more accurate and robust to changing light conditions. This thesis proposes several scene recognition approaches using combined data from the camera and 3D LiDAR sensor. These approaches are combined with RatSLAM to build an improved biologically inspired SLAM system. All proposed methods are tested on performance using several evaluation metrics and compared with visual scene recognition and OpenRatSLAM. As the results show, the suggested methods are capable of accurate and robust scene recognition, and final SLAM systems are able to construct suitable experience maps. Furthermore, all proposed approaches outperformed the OpenRatSLAM in most of the evaluated metrics and worked smoothly also in situations where OpenRatSLAM failed.


\makeatletter
\ifthenelse{\pdf@strcmp{\languagename}{english}=0}
{\renewcommand{\abstractname}{Kurzfassung}}
{\renewcommand{\abstractname}{Abstract}}
\makeatother

\chapter{\abstractname}

\begin{otherlanguage}{ngerman}
    %TODO: German Abstract
    Hier geht die Kurzfassung

\end{otherlanguage}


\makeatletter
\ifthenelse{\pdf@strcmp{\languagename}{english}=0}
{\renewcommand{\abstractname}{Abstract}}
{\renewcommand{\abstractname}{Kurzfassung}}
\makeatother