\section{Discussion}\label{section:Discussion}

Both suggested algorithms were tested for performance in different aspects in different environments and showed satisfactory results in every measured evaluation metric. Surprisingly, the approach that uses only the first stage of the place recognition process showed almost identical accuracy to the technique with both stages. Furthermore, the first stage-only approach significantly outperformed the both-stage method in terms of consumed memory and slightly in terms of computation time. However, the 2-stage technique proved an ability to eliminate some scenes wrongly classified by the first stage and also showed slightly better accuracy.\par
Based on these conclusions, the approach with only the first stage is recommended for lower-performance devices, especially in applications with significantly limited memory. This approach usually consumes approximately ten times less memory, and the difference in computation time is also non-negligible. However, if the performance is not the decisive factor, applying the second brings benefits in slightly improved accuracy.\par
As shown in section \ref{section:RatSalmIntegration}, both approaches proved to be suitable for a local view matching in the RatSLAM algorithm. During the simulation, the process produced stable result trajectories, very similar to the exact ones generated by the simulator.\par
Both approaches also proved a solid ability to generalization to different environments. For every metric, the results from the environment used for model training and the automatical tuning of parameters were very similar to those from diametrally different environments. In some metrics, the results in the other environments were also better than the results in the warehouse environment used in the development process. This proves that the approach is applicable in almost any indoor environment.\par
The approaches suggested in this work were also compared to the visual scene recognition used in the OpenRatSLAM approach. The combination of the LiDAR sensor and a camera proved to bring significant benefits compared to the usage of a single camera. The technique using the combination of camera and LiDAR showed significantly better accuracy than the visual scene recognition, especially in a house environment, where the accuracy achieved by suggested approaches was more than twice higher. Furthermore, all the errors produced by methods suggested in this work were close to the threshold, so all the wrongly evaluated matches were still pretty close to each other. On the other hand, the errors produced by the visual scene recognition were considerably larger, sometimes up to 10 times, which very negatively influences the final results produced by RatSLAM.\par
Memory consumption is another significant advantage of the suggested approaches over visual scene recognition. Not only are templates produced by the first-stage only approach five to six times smaller, but the average number of stored local views is also significantly smaller by both suggested approaches, which brings together huge memory savings, especially in the long run.\par
The computation time is the only metric in which the visual scene recognition outperformed suggested algorithms. However, because of the sensors' lower frequency and the smaller number of stored local views, thus a lower count of scene recognition executions, the total consumption of the computational resources is still comparable.\par
According to these results, the addition of a 3D LiDAR sensor showed significantly beneficial. This was proved especially in the hospital environment, see Figure \ref{fig:mapsHospital}, where the errors produced by visual scene recognition were so significant that the whole SLAM algorithm completely failed, but the approaches suggested in this approach still generated satisfactory results.
